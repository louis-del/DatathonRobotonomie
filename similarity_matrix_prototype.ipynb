{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models optimized for semantic textual similarity can be found at:\n",
    "# https://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/edit#gid=0\n",
    "#distiluse-base-multilingual-cased-v1\n",
    "#model = SentenceTransformer('stsb-roberta-large')\n",
    "#https://www.sbert.net/docs/pretrained_models.html\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make a small set of paragraphs, in later versions we will read these in from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a similarity matrix for a set of 10 texts\n",
    "# 1. Create a list of lists\n",
    "list_of_paragraphs = [[\"riding my bike in the mountains\"],\n",
    "                      [\"on a canal in the Bourgogne area\"],\n",
    "                      [\"on a boat on the Rhone river\"],\n",
    "                      [\"on taking a walk oh a hill\"],\n",
    "                      [\"cycling on a trail\"],\n",
    "                      [\"on a river near dijon\"],\n",
    "                      [\"faire du v√©lo dans les montagnes\"],\n",
    "                      [\"In the grand canyon\"],\n",
    "                      [\"at the washington monument\"],\n",
    "                      [\"at the lincoln memorial\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.empty([10,512])\n",
    "sim_matrix = np.empty([10,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_of_paragraphs)):\n",
    "    #print(list_of_paragraphs[i])\n",
    "    sentence_embedding = model.encode(list_of_paragraphs[i], convert_to_tensor=True)\n",
    "    embeddings[i] = sentence_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_of_paragraphs)):\n",
    "    for j in range(len(list_of_paragraphs)):\n",
    "        sim_matrix[i,j]=cosine_similarity([embeddings[i],embeddings[j]])[0,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sim_matrix,cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find trajectory in matrix to visit different similar photo pairs\n",
    "* present sequence in a coheret interaction scenario\n",
    "* use french language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: I like pizza because I love italian food\n",
      "Similarity score: 0.4194733500480652\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"I like Python because I can build AI applications\"\n",
    "sentence2 = \"I like pizza because I love italian food\"\n",
    "\n",
    "# encode sentences to get their embeddings\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "print(\"Sentence 1:\", sentence1)\n",
    "print(\"Sentence 2:\", sentence2)\n",
    "print(\"Similarity score:\", cosine_scores.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic similarity between two lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.6948120594024658\n",
      "\n",
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: 0.01910119690001011\n",
      "\n",
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: This is a picture of a favorite place on Mount Koya, near Kobe\n",
      "Similarity Score: 0.03388866409659386\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.021911118179559708\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: 0.5934419631958008\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: This is a picture of a favorite place on Mount Koya, near Kobe\n",
      "Similarity Score: 0.09048700332641602\n",
      "\n",
      "Sentence 1: I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.15659910440444946\n",
      "\n",
      "Sentence 1: I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: 0.046552132815122604\n",
      "\n",
      "Sentence 1: I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\n",
      "Sentence 2: This is a picture of a favorite place on Mount Koya, near Kobe\n",
      "Similarity Score: 0.24325820803642273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"I like Python because I can build AI applications\", \"The cat sits on the ground\",\"I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\"]   \n",
    "sentences2 = [\"I like Python because I can do data analytics\", \"The cat walks on the sidewalk\",\"This is a picture of a favorite place on Mount Koya, near Kobe\"]\n",
    "\n",
    "# encode list of sentences to get their embeddings\n",
    "embedding1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "for i in range(len(sentences1)):\n",
    "    for j in range(len(sentences2)):\n",
    "        print(\"Sentence 1:\", sentences1[i])\n",
    "        print(\"Sentence 2:\", sentences2[j])\n",
    "        print(\"Similarity Score:\", cosine_scores[i][j].item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Top K most similar sentences from a corpus given a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I like Python because I can build AI applications\",\n",
    "          \"I like Python because I can do data analytics\",\n",
    "          \"The cat sits on the ground\",\n",
    "         \"The cat walks on the sidewalk\",\n",
    "         \"I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\",\n",
    "         \"This is a picture of a favorite place on Mount Koya, near Kobe\"]\n",
    "\n",
    "# encode corpus to get corpus embeddings\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Saicho went to Mount Hiei near Kyoto\"\n",
    "\n",
    "# encode sentence to get sentence embeddings\n",
    "sentence_embedding = model.encode(sentence, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Saicho went to Mount Hiei near Kyoto \n",
      "\n",
      "Top 2 most similar sentences in corpus:\n",
      "I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto (Score: 0.4942)\n",
      "This is a picture of a favorite place on Mount Koya, near Kobe (Score: 0.4589)\n"
     ]
    }
   ],
   "source": [
    "# top_k results to return\n",
    "top_k=2\n",
    "\n",
    "# compute similarity scores of the sentence with the corpus\n",
    "cos_scores = util.pytorch_cos_sim(sentence_embedding, corpus_embeddings)[0]\n",
    "\n",
    "# Sort the results in decreasing order and get the first top_k\n",
    "top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "print(\"Sentence:\", sentence, \"\\n\")\n",
    "print(\"Top\", top_k, \"most similar sentences in corpus:\")\n",
    "for idx in top_results[0:top_k]:\n",
    "    print(corpus[idx], \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
